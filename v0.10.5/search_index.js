var documenterSearchIndex = {"docs":
[{"location":"95-reference/#reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"95-reference/#Contents","page":"Reference","title":"Contents","text":"","category":"section"},{"location":"95-reference/","page":"Reference","title":"Reference","text":"Pages = [\"95-reference.md\"]","category":"page"},{"location":"95-reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"95-reference/","page":"Reference","title":"Reference","text":"Pages = [\"95-reference.md\"]","category":"page"},{"location":"95-reference/#OpenCL.Const","page":"Reference","title":"OpenCL.Const","text":"Const(A::CLDeviceArray)\n\nMark a CLDeviceArray as constant/read-only. The invariant guaranteed is that you will not modify an CLDeviceArray for the duration of the current kernel.\n\nThis API can only be used on devices with compute capability 3.5 or higher.\n\nwarning: Warning\nExperimental API. Subject to change without deprecation.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#OpenCL.OutOfGPUMemoryError","page":"Reference","title":"OpenCL.OutOfGPUMemoryError","text":"OutOfGPUMemoryError()\n\nAn operation allocated too much GPU memory.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#Base.resize!-Union{Tuple{T}, Tuple{CLArray{T, 1}, Integer}} where T","page":"Reference","title":"Base.resize!","text":"resize!(a::CLVector, n::Integer)\n\nResize a to contain n elements. If n is smaller than the current collection length, the first n elements will be retained. If n is larger, the new elements are not guaranteed to be initialized.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#Base.unsafe_wrap-Union{Tuple{N}, Tuple{T}, Tuple{Type{Array}, CLArray{T, N}}} where {T, N}","page":"Reference","title":"Base.unsafe_wrap","text":"unsafe_wrap(Array, arr::CLArray)\n\nWrap a Julia Array around the buffer that backs a CLArray. This is only possible if the GPU array is backed by host memory, such as unified (host or shared) memory, or shared virtual memory.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#OpenCL.format-Tuple{String}","page":"Reference","title":"OpenCL.format","text":"Format string using dict-like variables, replacing all accurancies of %(key) with value.\n\nExample:     s = \"Hello, %(name)\"     format(s, name=\"Tom\")  ==> \"Hello, Tom\"\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#OpenCL.kernel_convert","page":"Reference","title":"OpenCL.kernel_convert","text":"kernel_convert(x)\n\nThis function is called for every argument to be passed to a kernel, allowing it to be converted to a GPU-friendly format. By default, the function does nothing and returns the input object x as-is.\n\nDo not add methods to this function, but instead extend the underlying Adapt.jl package and register methods for the the OpenCL.KernelAdaptor type.\n\n\n\n\n\n","category":"function"},{"location":"95-reference/#OpenCL.return_type-Tuple{Any, Any}","page":"Reference","title":"OpenCL.return_type","text":"OpenCL.return_type(f, tt) -> r::Type\n\nReturn a type r such that f(args...)::r where args::tt.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#OpenCL.cl.CLPtr","page":"Reference","title":"OpenCL.cl.CLPtr","text":"CLPtr{T}\n\nA memory address that refers to data of type T that is accessible from q device. A CLPtr is ABI compatible with regular Ptr objects, e.g. it can be used to ccall a function that expects a Ptr to device memory, but it prevents erroneous conversions between the two.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#OpenCL.cl.PtrOrCLPtr","page":"Reference","title":"OpenCL.cl.PtrOrCLPtr","text":"PtrOrCLPtr{T}\n\nA special pointer type, ABI-compatible with both Ptr and CLPtr, for use in ccall expressions to convert values to either a device or a host type (in that order). This is required for APIs which accept pointers that either point to host or device memory.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#OpenCL.cl.UnifiedDeviceMemory","page":"Reference","title":"OpenCL.cl.UnifiedDeviceMemory","text":"UnifiedDeviceMemory\n\nA buffer of device memory, owned by a specific device. Generally, may only be accessed by the device that owns it.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#OpenCL.cl.UnifiedHostMemory","page":"Reference","title":"OpenCL.cl.UnifiedHostMemory","text":"UnifiedHostMemory\n\nA buffer of memory on the host. May be accessed by the host, and all devices within the host driver. Frequently used as staging areas to transfer data to or from devices.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#OpenCL.cl.UnifiedSharedMemory","page":"Reference","title":"OpenCL.cl.UnifiedSharedMemory","text":"UnifiedSharedMemory\n\nA managed buffer that is shared between the host and one or more devices.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#OpenCL.cl.@checked-Tuple{Any}","page":"Reference","title":"OpenCL.cl.@checked","text":"@checked function foo(...)\n    rv = ...\n    return rv\nend\n\nMacro for wrapping a function definition returning a status code. Two versions of the function will be generated: foo, with the function body wrapped by an invocation of the check function (to be implemented by the caller of this macro), and unchecked_foo where no such invocation is present and the status code is returned to the caller.\n\n\n\n\n\n","category":"macro"},{"location":"01-profiling/#Profiling","page":"Profiling","title":"Profiling","text":"","category":"section"},{"location":"01-profiling/","page":"Profiling","title":"Profiling","text":"OpenCL.jl applications can be profiled using opencl-kernel-profiler, which is based on Perfetto. The most convenient way to use it is through opencl_kernel_profiler_jll by setting the OPENCL_LAYERS environment variable before initializing OpenCL as follows:","category":"page"},{"location":"01-profiling/","page":"Profiling","title":"Profiling","text":"using opencl_kernel_profiler_jll\nENV[\"OPENCL_LAYERS\"] = opencl_kernel_profiler_jll.libopencl_kernel_profiler","category":"page"},{"location":"01-profiling/","page":"Profiling","title":"Profiling","text":"By default, traces are limited to 1024 KB. To increase this limit, set CLKP_TRACE_MAX_SIZE to a larger value, e.g. ENV[\"CLKP_TRACE_MAX_SIZE\"] = \"100 * 1024\" for 100 MB.","category":"page"},{"location":"01-profiling/","page":"Profiling","title":"Profiling","text":"After the Julia session exits, traces will be written to opencl-kernel-profiler.trace in the current directory, which can be changed using the CLKP_TRACE_DEST environment variable. These traces can then be visualized by going to https://ui.perfetto.dev/ and opening the trace file.","category":"page"},{"location":"01-profiling/","page":"Profiling","title":"Profiling","text":"opencl-kernel-profiler works by intercepting calls to the OpenCL API and recording the execution time of kernels as well as events on the host side. It will also log the OpenCL/SPIR-V source code of the kernels alongside the traced calls to clEnqueueNDRangekernel, which can be useful for debugging.","category":"page"},{"location":"#OpenCL","page":"OpenCL","title":"OpenCL","text":"","category":"section"},{"location":"","page":"OpenCL","title":"OpenCL","text":"Julia interface for the OpenCL parallel computation API","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"This package aims to be a complete solution for OpenCL programming in Julia, similar in scope to [PyOpenCL] for Python. It provides a high level API for OpenCL to make programing hardware accelerators, such as GPUs, FPGAs, and DSPs, as well as multicore CPUs much less onerous.","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"note: OpenCL.jl needs your help!\nIf you can help maintain this package, please reach out on the JuliaLang Slack #gpu channel.","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"warning: OpenCL.jl is currently undergoing major changes.\nIf you have old code developed for OpenCL.jl v0.9, please check NEWS.md for an overview of the changes.","category":"page"},{"location":"#Installation","page":"OpenCL","title":"Installation","text":"","category":"section"},{"location":"","page":"OpenCL","title":"OpenCL","text":"Install an OpenCL driver. You can install one system-wide, i.e., using your package manager, or use pocl_jll.jl for a CPU back-end.\nAdd OpenCL to your Julia environment:","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"using Pkg\nPkg.add(\"OpenCL\")","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"Test your installation:","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"julia> OpenCL.versioninfo()\nOpenCL.jl version 0.10.0\n\nToolchain:\n - Julia v1.10.5\n - OpenCL_jll v2024.5.8+1\n\nAvailable platforms: 3\n - Portable Computing Language\n   version: OpenCL 3.0 PoCL 6.0  Linux, Release, RELOC, SPIR-V, LLVM 15.0.7jl, SLEEF, DISTRO, POCL_DEBUG\n   · cpu-haswell-AMD Ryzen 9 5950X 16-Core Processor (fp64, il)\n - NVIDIA CUDA\n   version: OpenCL 3.0 CUDA 12.6.65\n   · NVIDIA RTX 6000 Ada Generation (fp64)\n - Intel(R) OpenCL Graphics\n   version: OpenCL 3.0\n   · Intel(R) Arc(TM) A770 Graphics (fp16, il)","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"warning: Platform list is only computed once\nOpenCL is only computing the list of platforms once. Therefore if using pocl_jll is executed after OpenCL.versioninfo() or other calls to the OpenCL API then it won't affect the list of platforms available and you will need to restart the Julia session and run using pocl_jll before OpenCL is used.","category":"page"},{"location":"#Basic-example:-vector-add","page":"OpenCL","title":"Basic example: vector add","text":"","category":"section"},{"location":"","page":"OpenCL","title":"OpenCL","text":"The traditional way of using OpenCL is by writing kernel source code in OpenCL C. For example, a simple vector addition:","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"using OpenCL, pocl_jll\n\nconst source = \"\"\"\n   __kernel void vadd(__global const float *a,\n                      __global const float *b,\n                      __global float *c) {\n      int gid = get_global_id(0);\n      c[gid] = a[gid] + b[gid];\n    }\"\"\"\n\na = rand(Float32, 50_000)\nb = rand(Float32, 50_000)\n\nd_a = CLArray(a)\nd_b = CLArray(b)\nd_c = similar(d_a)\n\np = cl.Program(; source) |> cl.build!\nk = cl.Kernel(p, \"vadd\")\n\nclcall(k, Tuple{CLPtr{Float32}, CLPtr{Float32}, CLPtr{Float32}},\n       d_a, d_b, d_c; global_size=size(a))\n\nc = Array(d_c)\n\n@assert a + b ≈ c","category":"page"},{"location":"#Native-example:-vector-add","page":"OpenCL","title":"Native example: vector add","text":"","category":"section"},{"location":"","page":"OpenCL","title":"OpenCL","text":"If your platform supports SPIR-V, it's possible to use Julia functions as kernels:","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"using OpenCL, pocl_jll\n\nfunction vadd(a, b, c)\n    gid = get_global_id(1)\n    @inbounds c[gid] = a[gid] + b[gid]\n    return\nend\n\na = rand(Float32, 50_000)\nb = rand(Float32, 50_000)\n\nd_a = CLArray(a)\nd_b = CLArray(b)\nd_c = similar(d_a)\n\n@opencl global_size=size(a) vadd(d_a, d_b, d_c)\n\nc = Array(d_c)\n\n@assert a + b ≈ c","category":"page"},{"location":"#More-examples","page":"OpenCL","title":"More examples","text":"","category":"section"},{"location":"","page":"OpenCL","title":"OpenCL","text":"You may want to check out the examples folder. Either git clone the repository to your local machine or navigate to the OpenCL.jl install directory via:","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"using OpenCL\ncd(joinpath(dirname(pathof(OpenCL)), \"..\"))","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"Otherwise, feel free to take a look at the Jupyter notebooks below:","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"Julia set fractals\nMandlebrot fractal\nTranspose bandwidth","category":"page"},{"location":"#Credit","page":"OpenCL","title":"Credit","text":"","category":"section"},{"location":"","page":"OpenCL","title":"OpenCL","text":"This package is heavily influenced by the work of others:","category":"page"},{"location":"","page":"OpenCL","title":"OpenCL","text":"PyOpenCL by Andreas Klockner\noclpb by Sean Ross\nBoost.Compute by Kyle Lutz\nrust-opencl","category":"page"}]
}
